{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888d46b3",
   "metadata": {},
   "source": [
    "## Импорты и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e8faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "from data_structures import Example\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from hierarchical_optimizer import HierarchicalOptimizer\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9fea28",
   "metadata": {},
   "source": [
    "## Подготовка датасета\n",
    "Создаем простой датасет для демонстрации (задача классификации тональности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00eaecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared:\n",
      "  Train: 18 examples\n",
      "  Validation: 2 examples\n",
      "  Test: 20 examples\n"
     ]
    }
   ],
   "source": [
    "LABEL_MAP = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "def load_jsonl(path: str) -> List[Dict]:\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def to_examples(data):\n",
    "    return [\n",
    "        Example(input_text=item[\"text\"], expected_output=LABEL_MAP[item[\"label\"]])\n",
    "        for item in data\n",
    "    ]\n",
    "\n",
    "def train_val_split(data, val_ratio=0.1, seed=42):\n",
    "    random.Random(seed).shuffle(data)\n",
    "\n",
    "    split_idx = int(len(data) * (1 - val_ratio))\n",
    "    train_data = data[:split_idx]\n",
    "    val_data = data[split_idx:]\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "def sample_n(data, n=100, seed=42):\n",
    "    rnd = random.Random(seed)\n",
    "    return rnd.sample(data, min(n, len(data)))\n",
    "\n",
    "train_data = sample_n(load_jsonl(\"data/train.jsonl\"), 20)\n",
    "test_data = sample_n(load_jsonl(\"data/test.jsonl\"), 20)\n",
    "\n",
    "train_split, val_split = train_val_split(train_data, val_ratio=0.1, seed=42)\n",
    "\n",
    "train_examples = to_examples(train_split)\n",
    "validation_examples = to_examples(val_split)\n",
    "test_examples = to_examples(test_data)\n",
    "\n",
    "print(\"Dataset prepared:\")\n",
    "print(f\"  Train: {len(train_examples)} examples\")\n",
    "print(f\"  Validation: {len(validation_examples)} examples\")\n",
    "print(f\"  Test: {len(test_examples)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506755da",
   "metadata": {},
   "source": [
    "## Создание начального промпта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9f5e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prompt:\n",
      "------------------------------------------------------------\n",
      "Determine whether the Statement is a lie (Yes) or not (No) based on the Context and other information.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_prompt = \"\"\"Determine whether the Statement is a lie (Yes) or not (No) based on the Context and other information.\"\"\"\n",
    "\n",
    "print(\"Initial prompt:\")\n",
    "print(\"-\" * 60)\n",
    "print(initial_prompt)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8902c14",
   "metadata": {},
   "source": [
    "## Инициализация оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7384e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = HierarchicalOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d6ed0",
   "metadata": {},
   "source": [
    "## Запуск оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30001454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating initial prompt...\n",
      "Initial score: 0.650\n",
      "  Accuracy: 0.500\n",
      "  Safety: 1.000\n",
      "  Robustness: 0.750\n",
      "  Efficiency: 0.000\n",
      "  F1: 0.000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATION 1/3\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Local Optimization\n",
      "  Population size: 1\n",
      "\n",
      "  Optimizing node 1/1 (score: 0.650)\n",
      "\n",
      "============================================================\n",
      "Starting Local Optimization\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 2 unique\n",
      "Generated 2 candidate prompts\n",
      "  Evaluating candidate 1/2... Score: 0.460\n",
      "  Evaluating candidate 2/2... Score: 0.650\n",
      "Evaluated 2 candidates\n",
      "Best candidate score: 0.650 (Δ +0.000)\n",
      "✗ No significant improvement\n",
      "Iteration time: 64.34s — LLM calls: 19 (total: 27)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 2 unique\n",
      "Generated 2 candidate prompts\n",
      "  Evaluating candidate 1/2... Score: 0.670\n",
      "  Evaluating candidate 2/2... Score: 0.870\n",
      "Evaluated 2 candidates\n",
      "Best candidate score: 0.870 (Δ +0.220)\n",
      "✓ Improvement found! New best: 0.870\n",
      "Iteration time: 55.28s — LLM calls: 19 (total: 46)\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 2 unique\n",
      "Generated 2 candidate prompts\n",
      "  Evaluating candidate 1/2... Score: 0.770\n",
      "  Evaluating candidate 2/2... Score: 0.965\n",
      "Evaluated 2 candidates\n",
      "Best candidate score: 0.965 (Δ +0.095)\n",
      "✓ Improvement found! New best: 0.965\n",
      "Iteration time: 75.55s — LLM calls: 19 (total: 65)\n",
      "\n",
      "============================================================\n",
      "Local Optimization Complete\n",
      "Final score: 0.965\n",
      "Improvements: 2\n",
      "============================================================\n",
      "\n",
      "\n",
      "Phase 2: Global Optimization (Skipped)\n",
      "\n",
      "Phase 3: Population Update\n",
      "\n",
      "  Generation best: 0.965\n",
      "  Overall best: 0.650\n",
      "  ✓ Improvement: +0.315\n",
      "\n",
      "  Generation time: 198.89s\n",
      "\n",
      "================================================================================\n",
      "GENERATION 2/3\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Local Optimization\n",
      "  Population size: 1\n",
      "\n",
      "  Optimizing node 1/1 (score: 0.965)\n",
      "\n",
      "============================================================\n",
      "Starting Local Optimization\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 1 unique\n",
      "Generated 1 candidate prompts\n",
      "  Evaluating candidate 1/1... Score: 0.370\n",
      "Evaluated 1 candidates\n",
      "Best candidate score: 0.370 (Δ -0.595)\n",
      "✗ No significant improvement\n",
      "Iteration time: 51.44s — LLM calls: 11 (total: 82)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 2 unique\n",
      "Generated 2 candidate prompts\n",
      "  Evaluating candidate 1/2... Score: 0.560\n",
      "  Evaluating candidate 2/2... Score: 0.570\n",
      "Evaluated 2 candidates\n",
      "Best candidate score: 0.570 (Δ -0.395)\n",
      "✗ No significant improvement\n",
      "Iteration time: 93.26s — LLM calls: 19 (total: 101)\n",
      "\n",
      "Early stopping after 2 iterations without improvement\n",
      "\n",
      "============================================================\n",
      "Local Optimization Complete\n",
      "Final score: 0.965\n",
      "Improvements: 2\n",
      "============================================================\n",
      "\n",
      "\n",
      "Phase 2: Global Optimization (Triggered)\n",
      "\n",
      "============================================================\n",
      "GLOBAL OPTIMIZATION STEP | Generation 2\n",
      "============================================================\n",
      "Step 1: Analyzing optimization history...\n",
      "Error in global optimization: GlobalOptimizer._find_common_subsequences() missing 1 required positional argument: 'min_length'\n",
      "\n",
      "Phase 3: Population Update\n",
      "\n",
      "  Generation best: 0.965\n",
      "  Overall best: 0.965\n",
      "  ✗ No significant improvement\n",
      "\n",
      "  Generation time: 144.72s\n",
      "\n",
      "================================================================================\n",
      "GENERATION 3/3\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Local Optimization\n",
      "  Population size: 1\n",
      "\n",
      "  Optimizing node 1/1 (score: 0.965)\n",
      "\n",
      "============================================================\n",
      "Starting Local Optimization\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 1 unique\n",
      "Generated 1 candidate prompts\n",
      "  Evaluating candidate 1/1... Score: 0.465\n",
      "Evaluated 1 candidates\n",
      "Best candidate score: 0.465 (Δ -0.500)\n",
      "✗ No significant improvement\n",
      "Iteration time: 53.01s — LLM calls: 11 (total: 112)\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Failures: 2, Successes: 0\n",
      "Generating text gradients...\n",
      "Generated 1 gradients\n",
      "  Generating variants from gradient 1/1\n",
      "  Generated 2 variants, 2 unique\n",
      "Generated 2 candidate prompts\n",
      "  Evaluating candidate 1/2... Score: 0.875\n",
      "  Evaluating candidate 2/2... Score: 0.775\n",
      "Evaluated 2 candidates\n",
      "Best candidate score: 0.875 (Δ -0.090)\n",
      "✗ No significant improvement\n",
      "Iteration time: 92.61s — LLM calls: 19 (total: 131)\n",
      "\n",
      "Early stopping after 2 iterations without improvement\n",
      "\n",
      "============================================================\n",
      "Local Optimization Complete\n",
      "Final score: 0.965\n",
      "Improvements: 2\n",
      "============================================================\n",
      "\n",
      "\n",
      "Phase 2: Global Optimization (Skipped)\n",
      "\n",
      "Phase 3: Population Update\n",
      "\n",
      "  Generation best: 0.965\n",
      "  Overall best: 0.965\n",
      "  ✗ No significant improvement\n",
      "\n",
      "  Generation time: 152.43s\n",
      "\n",
      "================================================================================\n",
      "EARLY STOPPING\n",
      "No improvement for 2 generations\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Results:\n",
      "  Initial score: 0.650\n",
      "  Final score: 0.965\n",
      "  Improvement: +0.315 (48.5%)\n",
      "  Total time: 509.59s\n",
      "  Generations: 3\n",
      "\n",
      "Test Set Evaluation:\n",
      "  Test score: 0.829\n",
      "  Test accuracy: 0.950\n",
      "History saved to ./optimization_results/optimization_history.json (13 nodes)\n",
      "\n",
      "Results saved to: ./optimization_results\n",
      "  - optimization_history.json\n",
      "  - optimization_report.json\n",
      "  - best_prompt.txt\n",
      "  - trajectory.txt\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_node = optimizer.optimize(\n",
    "    initial_prompt=initial_prompt,\n",
    "    train_examples=train_examples,\n",
    "    validation_examples=validation_examples,\n",
    "    test_examples=test_examples,\n",
    "    save_dir=\"./optimization_results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010feee",
   "metadata": {},
   "source": [
    "## Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ffcd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization generations summary:\n",
      "  Generation 1: time 198.89s, best_score 0.965\n",
      "  Generation 2: time 144.72s, best_score 0.965\n",
      "  Generation 3: time 152.43s, best_score 0.965\n",
      "Local optimizer summary:\n",
      "  Total iterations recorded: 7\n",
      "  Avg iteration time: 69.36s\n",
      "  Total LLM calls attributed to local iterations: 117\n",
      "Per-iteration breakdown:\n",
      "  Iter 1: time 64.34s, llm_calls 19\n",
      "  Iter 2: time 55.28s, llm_calls 19\n",
      "  Iter 3: time 75.55s, llm_calls 19\n",
      "  Iter 1: time 51.44s, llm_calls 11\n",
      "  Iter 2: time 93.26s, llm_calls 19\n",
      "  Iter 1: time 53.01s, llm_calls 11\n",
      "  Iter 2: time 92.61s, llm_calls 19\n"
     ]
    }
   ],
   "source": [
    "report = optimizer.get_optimization_report()\n",
    "print('Optimization generations summary:')\n",
    "for entry in report['optimization_log']:\n",
    "    print(f\"  Generation {entry['generation']}: time {entry['time']:.2f}s, best_score {entry['best_score']:.3f}\")\n",
    "\n",
    "local_stats = report['component_statistics']['local_optimizer']\n",
    "print('Local optimizer summary:')\n",
    "print(f\"  Total iterations recorded: {local_stats.get('total_iterations', 0)}\")\n",
    "avg_it = local_stats.get('avg_iteration_time')\n",
    "if avg_it is not None:\n",
    "    print(f\"  Avg iteration time: {avg_it:.2f}s\")\n",
    "else:\n",
    "    print('  Avg iteration time: N/A')\n",
    "print(f\"  Total LLM calls attributed to local iterations: {local_stats.get('total_llm_calls_by_local', 0)}\")\n",
    "print('Per-iteration breakdown:')\n",
    "for s in local_stats.get('iteration_stats', []):\n",
    "    print(f\"  Iter {s['iteration']}: time {s['time']:.2f}s, llm_calls {s['llm_calls']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94007335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PROMPT FOUND:\n",
      "================================================================================\n",
      "Evaluate the statement below and determine if it is a lie (Yes) or not (No). When making your assessment, please adhere to the following detailed criteria:\n",
      "\n",
      "1. **Contextual Analysis**: Examine the broader context in which the statement is made, including the political environment. Is there a significant political backdrop that could affect perception?\n",
      "   \n",
      "2. **Tone and Language**: Analyze the language used in the statement. Does it carry partisan connotations or suggest bias? Is it emotionally charged or neutral?\n",
      "   \n",
      "3. **Truthfulness vs. Exaggeration**: Determine if the statement is factually accurate or if it involves exaggeration. Consider if the statement presents a distorted view of facts to enhance the subject's image.\n",
      "\n",
      "4. **Implications for Public Perception**: Reflect on the potential impact of the statement on public opinion. How might it affect the credibility of the speaker and their associated political party?\n",
      "\n",
      "**Evaluation Guidance**: \n",
      "- Rate each criterion on a scale of 1 (low relevance) to 5 (high relevance). \n",
      "- A total score of 12-20 indicates a higher likelihood of the statement being a lie.\n",
      "\n",
      "Example Assessment:\n",
      "Statement: \"The Supreme Court ruled 15 times that marriage is a fundamental right.\"\n",
      "Context: Discussed in a Republican candidate's interview.\n",
      "Contextual Analysis: 4\n",
      "Tone and Language: 3\n",
      "Truthfulness vs. Exaggeration: 5\n",
      "Implications for Public Perception: 4\n",
      "Total Score: 16\n",
      "Expected Assessment: Yes (indicating potential exaggeration).\n",
      "\n",
      "Now analyze the following:\n",
      "Statement: [Your statement here]\n",
      "Job title: [Job title here]\n",
      "State: [State here]\n",
      "Party: [Party here]\n",
      "Context: [Context here]\n",
      "================================================================================\n",
      "Score: 0.965\n",
      "Generation: 2\n",
      "Source: local\n"
     ]
    }
   ],
   "source": [
    "print(\"BEST PROMPT FOUND:\")\n",
    "print(\"=\" * 80)\n",
    "print(best_node.prompt_text)\n",
    "print(\"=\" * 80)\n",
    "print(f\"Score: {best_node.metrics.composite_score():.3f}\")\n",
    "print(f\"Generation: {best_node.generation}\")\n",
    "print(f\"Source: {best_node.source.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beea1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS:\n",
      "  Composite Score: 0.965\n",
      "  Accuracy:        1.000\n",
      "  Safety:          1.000\n",
      "  Robustness:      0.825\n",
      "  Efficiency:      0.000\n",
      "  F1 Score:        0.000\n"
     ]
    }
   ],
   "source": [
    "metrics = best_node.metrics\n",
    "\n",
    "print(\"METRICS:\")\n",
    "print(f\"  Composite Score: {metrics.composite_score():.3f}\")\n",
    "print(f\"  Accuracy:        {metrics.metrics['accuracy']:.3f}\")\n",
    "print(f\"  Safety:          {metrics.metrics['safety']:.3f}\")\n",
    "print(f\"  Robustness:      {metrics.metrics['robustness']:.3f}\")\n",
    "print(f\"  Efficiency:      {metrics.metrics['efficiency']:.3f}\")\n",
    "print(f\"  F1 Score:        {metrics.metrics['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1698afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION TRAJECTORY\n",
      "================================================================================\n",
      "\n",
      "Generation | Best Score | Overall Best | Improvement\n",
      "------------------------------------------------------------\n",
      "   1       | 0.965      | 0.965       | +0.315 ████████████████████████████████████████████████\n",
      "   2       | 0.965      | 0.965       | +0.000 ████████████████████████████████████████████████\n",
      "   3       | 0.965      | 0.965       | +0.000 ████████████████████████████████████████████████\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.visualize_optimization_trajectory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ea85b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZATION REPORT:\n",
      "Overall Statistics:\n",
      "   Total time: 509.59s\n",
      "   Generations: 3\n",
      "   Total nodes explored: 13\n",
      "Component Statistics:\n",
      "   Local optimizer iterations: 7\n",
      "   Local improvements: 2\n",
      "   Global optimizer steps: 0\n",
      "   Successful global changes: 0\n",
      "Best Global Strategies:\n"
     ]
    }
   ],
   "source": [
    "report = optimizer.get_optimization_report()\n",
    "\n",
    "print(\"OPTIMIZATION REPORT:\")\n",
    "print(\"Overall Statistics:\")\n",
    "print(f\"   Total time: {report['optimization_info']['total_time_seconds']:.2f}s\")\n",
    "print(f\"   Generations: {report['optimization_info']['generations']}\")\n",
    "print(f\"   Total nodes explored: {report['component_statistics']['history']['total_nodes']}\")\n",
    "\n",
    "print(\"Component Statistics:\")\n",
    "print(f\"   Local optimizer iterations: {report['component_statistics']['local_optimizer']['total_iterations']}\")\n",
    "print(f\"   Local improvements: {report['component_statistics']['local_optimizer']['improvements_count']}\")\n",
    "print(f\"   Global optimizer steps: {report['component_statistics']['global_optimizer']['total_global_steps']}\")\n",
    "print(f\"   Successful global changes: {report['component_statistics']['global_optimizer']['successful_global_changes']}\")\n",
    "\n",
    "print(\"Best Global Strategies:\")\n",
    "for i, strategy in enumerate(report['best_global_strategies'][:3], 1):\n",
    "    print(f\"   {i}. {strategy['strategy']['type']}: Score {strategy['score']:.3f}\")\n",
    "    print(f\"      {strategy['strategy']['description'][:70]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efddb88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVOLUTION OF BEST PROMPT:\n",
      "================================================================================\n",
      "Step 0: Generation 0, Source: initial\n",
      "  Score: 0.650\n",
      "  ↓\n",
      "Step 1: Generation 1, Source: local\n",
      "  Score: 0.870\n",
      "  Operations:\n",
      "    - modify_instruction: Edited based on gradient...\n",
      "  ↓\n",
      "Step 2: Generation 2, Source: local\n",
      "  Score: 0.965\n",
      "  Operations:\n",
      "    - modify_instruction: Edited based on gradient...\n"
     ]
    }
   ],
   "source": [
    "lineage = optimizer.history.get_lineage(best_node.id)\n",
    "\n",
    "print(\"EVOLUTION OF BEST PROMPT:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, node in enumerate(lineage):\n",
    "    print(f\"Step {i}: Generation {node.generation}, Source: {node.source.value}\")\n",
    "    if node.is_evaluated:\n",
    "        print(f\"  Score: {node.metrics.composite_score():.3f}\")\n",
    "\n",
    "    if node.operations:\n",
    "        print(f\"  Operations:\")\n",
    "        for op in node.operations:\n",
    "            print(f\"    - {op.operation_type.value}: {op.description[:60]}...\")\n",
    "\n",
    "    if i < len(lineage) - 1:  \n",
    "        print(\"  ↓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbf09aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing with baseline...\n",
      "\n",
      "Comparison Results:\n",
      "  Baseline score: 0.424\n",
      "  Optimized score: 0.729\n",
      "  Improvement: +0.304\n",
      "COMPARISON WITH BASELINE:\n",
      "================================================================================\n",
      "Baseline:\n",
      "  composite_score     : 0.424\n",
      "  accuracy            : 0.200\n",
      "  safety              : 0.850\n",
      "  robustness          : 0.672\n",
      "  efficiency          : 0.000\n",
      "  f1                  : 0.000\n",
      "Optimized:\n",
      "  composite_score     : 0.729\n",
      "  accuracy            : 0.750\n",
      "  safety              : 0.550\n",
      "  robustness          : 0.845\n",
      "  efficiency          : 0.000\n",
      "  f1                  : 0.000\n",
      "Improvements:\n",
      "  composite_score     : +0.304 ↑\n",
      "  accuracy            : +0.550 ↑\n",
      "  safety              : -0.300 ↓\n",
      "  robustness          : +0.172 ↑\n",
      "  efficiency          : +0.000 →\n",
      "  f1                  : +0.000 →\n"
     ]
    }
   ],
   "source": [
    "comparison = optimizer.compare_with_baseline(\n",
    "    baseline_prompt=initial_prompt,\n",
    "    test_examples=test_examples\n",
    ")\n",
    "\n",
    "print(\"COMPARISON WITH BASELINE:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"Baseline:\")\n",
    "for metric, value in comparison['baseline'].items():\n",
    "    print(f\"  {metric:20s}: {value:.3f}\")\n",
    "\n",
    "print(\"Optimized:\")\n",
    "for metric, value in comparison['optimized'].items():\n",
    "    print(f\"  {metric:20s}: {value:.3f}\")\n",
    "\n",
    "print(\"Improvements:\")\n",
    "for metric, value in comparison['improvements'].items():\n",
    "    arrow = \"↑\" if value > 0 else \"↓\" if value < 0 else \"→\"\n",
    "    print(f\"  {metric:20s}: {value:+.3f} {arrow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb5d4299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "Overall Statistics:\n",
      "  Total nodes explored: 13\n",
      "  Evaluations performed: 13\n",
      "  Generations completed: 3\n",
      "  Best score achieved: 0.965\n",
      "  Average score: 0.665\n",
      "Local Optimization:\n",
      "  Total iterations: 7\n",
      "  Improvements found: 2\n",
      "  Success rate: 28.6%\n",
      "Global Optimization:\n",
      "  Total global steps: 0\n",
      "  Candidates generated: 0\n",
      "  Successful changes: 0\n",
      "  Success rate: 0.0%\n",
      "Optimization complete!\n",
      "   Results saved to: ./optimization_results/\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "history_stats = optimizer.history.get_statistics()\n",
    "local_stats = optimizer.local_optimizer.get_statistics()\n",
    "global_stats = optimizer.global_optimizer.get_statistics()\n",
    "\n",
    "print(\"Overall Statistics:\")\n",
    "print(f\"  Total nodes explored: {history_stats['total_nodes']}\")\n",
    "print(f\"  Evaluations performed: {history_stats['evaluated_nodes']}\")\n",
    "print(f\"  Generations completed: {history_stats['max_generation']}\")\n",
    "print(f\"  Best score achieved: {history_stats['best_score']:.3f}\")\n",
    "print(f\"  Average score: {history_stats['avg_score']:.3f}\")\n",
    "\n",
    "print(\"Local Optimization:\")\n",
    "print(f\"  Total iterations: {local_stats['total_iterations']}\")\n",
    "print(f\"  Improvements found: {local_stats['improvements_count']}\")\n",
    "print(f\"  Success rate: {local_stats['improvement_rate']:.1%}\")\n",
    "\n",
    "print(\"Global Optimization:\")\n",
    "print(f\"  Total global steps: {global_stats['total_global_steps']}\")\n",
    "print(f\"  Candidates generated: {global_stats['total_candidates_generated']}\")\n",
    "print(f\"  Successful changes: {global_stats['successful_global_changes']}\")\n",
    "print(f\"  Success rate: {global_stats['success_rate']:.1%}\")\n",
    "\n",
    "print(\"Optimization complete!\")\n",
    "print(f\"   Results saved to: ./optimization_results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
