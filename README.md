# Пайплайн оптимизации промптов

## Обзор системы

### Концепция

Система реализует автоматическую оптимизацию промптов для языковых моделей через иерархический эволюционный подход, основанный на концепции **текстовых градиентов**. В отличие от традиционных методов оптимизации, которые работают с числовыми градиентами в пространстве параметров, данная система использует LLM для анализа ошибок и генерации текстовых рекомендаций по улучшению промптов на естественном языке.

### Философия подхода

**Текстовые градиенты** — это основа системы. Когда промпт ошибается на определенных примерах, система не просто фиксирует факт ошибки, а использует LLM для глубокого анализа:
- Почему промпт ошибся?
- Какие паттерны ошибок наблюдаются?
- В каком направлении нужно двигаться для улучшения?
- Какие конкретные изменения следует внести?

Эти вопросы формулируются на естественном языке и обрабатываются другой LLM, которая генерирует структурированный анализ в виде текстового градиента. Градиент содержит не только диагностику проблемы, но и конкретные рекомендации по улучшению, которые затем применяются для генерации новых вариантов промпта.

### Двухуровневая архитектура оптимизации

Система работает на двух взаимодополняющих уровнях:

**1. Локальная оптимизация (градиентный поиск)**
- Фокусируется на точечных улучшениях текущего промпта
- Анализирует конкретные ошибки на обучающих примерах
- Генерирует текстовые градиенты для выявленных проблем
- Создает варианты улучшенных промптов на основе градиентов
- Итеративно отбирает лучшие варианты

**2. Глобальная оптимизация (структурные изменения)**
- Анализирует всю историю оптимизации для выявления паттернов
- Определяет застой и низкое разнообразие в популяции
- Генерирует высокоуровневые стратегии улучшения (комбинирование, реструктуризация, упрощение и т.д.)
- Применяет структурные изменения к промптам
- Запускается периодически или при обнаружении проблем

### Общий поток работы

Процесс оптимизации организован как эволюционный алгоритм с поколениями промптов:

1. **Инициализация**: Создается начальный промпт и оценивается на валидационном наборе
2. **Поколения**: Для каждого поколения:
   - **Локальная оптимизация**: Каждый промпт в популяции улучшается через градиентный поиск
     - Выявляются ошибки на обучающих примерах
     - Генерируются текстовые градиенты (анализ ошибок + рекомендации)
     - Создаются варианты промптов на основе градиентов
     - Оцениваются и отбираются лучшие варианты
   - **Глобальная оптимизация** (опционально): При необходимости применяются структурные изменения
     - Анализируется история оптимизации
     - Генерируются стратегии улучшения
     - Создаются новые промпты через комбинирование, реструктуризацию и т.д.
   - **Отбор популяции**: Выбираются лучшие промпты для следующего поколения
3. **Финальная оценка**: Лучший промпт оценивается на тестовом наборе

### Ключевые особенности

**Интеллектуальный анализ ошибок:**
- Кластеризация ошибок по типам для более эффективной обработки
- Контрастный анализ успешных и неуспешных примеров
- Учет контекста оптимизации (поколение, успешные операции в прошлом)

**Множественные метрики оценки:**
- Accuracy, F1, Safety, Robustness, Efficiency
- Композитная оценка как взвешенная сумма метрик
- Семантическая оценка через LLM-judge (не просто строковое сравнение)

**Управление историей:**
- Полное дерево эволюции промптов
- Отслеживание успешных операций и паттернов
- Обнаружение застоя и низкого разнообразия
- Pareto-front для множественных метрик

**Адаптивность:**
- Early stopping при отсутствии улучшений
- Динамический выбор стратегий на основе истории
- Балансировка между исследованием и эксплуатацией

### Преимущества подхода

1. **Интерпретируемость**: Текстовые градиенты объясняют, почему и как нужно улучшить промпт
2. **Гибкость**: Работает с любыми типами промптов без необходимости явного градиентного спуска
3. **Эффективность**: Фокусируется на конкретных ошибках, а не на случайном поиске
4. **Масштабируемость**: Может обрабатывать сложные задачи с множественными метриками
5. **Автоматизация**: Полностью автоматический процесс без ручного вмешательства

### Области применения

Система подходит для оптимизации промптов в различных задачах:
- Классификация текста
- Вопросно-ответные системы
- Генерация текста с ограничениями
- Задачи, требующие баланса между точностью, безопасностью и эффективностью

---

## Архитектура компонентов

### Основные компоненты

1. **HierarchicalOptimizer** (`hierarchical_optimizer.py`)
   - Координирует весь процесс оптимизации
   - Управляет поколениями промптов
   - Интегрирует локальную и глобальную оптимизацию

2. **LocalOptimizer** (`local_optimizer.py`)
   - Выполняет локальную оптимизацию на основе градиентов
   - Итеративно улучшает промпты

3. **GlobalOptimizer** (`global_optimizer.py`)
   - Анализирует историю оптимизации
   - Генерирует глобальные стратегии улучшения

4. **TextGradientGenerator** (`text_gradient_generator.py`)
   - **Ключевой компонент**: генерирует текстовые градиенты из примеров ошибок

5. **PromptEditor** (`prompt_editor.py`)
   - Применяет градиенты для создания новых вариантов промптов

6. **PromptScorer** (`evaluator/scorer.py`)
   - Оценивает промпты по множественным метрикам

7. **HistoryManager** (`history_manager.py`)
   - Отслеживает эволюцию промптов
   - Управляет деревом вариантов

---

## Детальный процесс работы пайплайна

### Фаза 1: Инициализация

### Создание оптимизатора
optimizer = HierarchicalOptimizer()

### Подготовка данных
`train_examples, validation_examples, test_examples, initial_prompt = data_fabric('squad_v2')`  

**Шаги:**
1. Создается `HierarchicalOptimizer` с инициализацией всех компонентов
2. Загружаются обучающие, валидационные и тестовые примеры
3. Создается начальный промпт (`PromptNode` с `generation=0`)
4. Начальный промпт оценивается на валидационном наборе

**Оценка включает:**
- Выполнение промпта на примерах
- Вычисление метрик: accuracy, safety, robustness, efficiency, f1
- Композитная оценка: взвешенная сумма метрик
- Разделение примеров на успешные и неуспешные

---

### Фаза 2: Основной цикл оптимизации (поколения)

Для каждого поколения (от 1 до `MAX_GENERATIONS`):

#### Этап 2.1: Локальная оптимизация

Для каждого промпта в текущей популяции:

##### Шаг 1: Выявление провалов

`failure_examples = self._get_failure_examples(current_best, train_examples)`

**Процесс:**
- Если промпт уже оценен, берутся провалы из `node.evaluation_examples["failures"]`
- Иначе промпт выполняется на обучающих примерах
- Фильтруются примеры, где `actual_output != expected_output` (проверка через LLM для семантической эквивалентности)
- Если провалов больше `LOCAL_BATCH_SIZE`, выбирается случайное подмножество

##### Шаг 2: Генерация текстовых градиентов

**Это ключевой этап системы!**  
`gradients = self._generate_gradients(current_best, failure_examples, success_examples)`

**Процесс генерации градиентов:**

**Вариант A: Кластеризация провалов (если провалов много)**

Если `len(failure_examples) > LOCAL_BATCH_SIZE * CLUSTERING_FAILURE_MULTIPLIER`:

1. **Кластеризация по типам ошибок:**
   clusters = self.cluster_failure_types(failure_examples)
      - LLM анализирует провалы и группирует их по типам ошибок
   - Используется промпт из `prompts/clustering.txt`
   - Результат: словарь `{тип_ошибки: [примеры]}`

2. **Генерация градиента для каждого кластера:**
   - Для каждого кластера создается отдельный градиент
   - Используется промпт из `prompts/analysis.txt`
   - LLM получает:
     - Текущий промпт
     - Примеры провалов из кластера
     - Примеры успехов (для контраста)
     - Контекст оптимизации (поколение, успешные операции)

**Вариант B: Батчевая генерация (если провалов немного)**

1. **Создание батчей:**
   - Провалы разбиваются на батчи размером `LOCAL_BATCH_SIZE`
   - Каждый батч обрабатывается отдельно

2. **Единый запрос к LLM:**
   - Используется `build_gradients_batch_prompt()`
   - LLM генерирует несколько градиентов за один вызов
   - Каждый градиент соответствует одному батчу/кластеру

**Структура текстового градиента:**  
TextGradient(  
    &emsp; failure_examples: List[Example],     # Примеры ошибок  
    &emsp; success_examples: List[Example],     # Примеры успехов (для контраста)  
    &emsp; error_analysis: str,                 # Анализ причин ошибок  
    &emsp; suggested_direction: str,            # Общее направление улучшения  
    &emsp; specific_suggestions: List[str],     # Конкретные рекомендации  
    &emsp; priority: float,                     # Приоритет (0.0-1.0)  
    &emsp; metadata: Dict                       # Дополнительная информация  
)  
**Парсинг ответа LLM:**

Ответ LLM парсится с помощью `GradientParser`:
- Извлекаются секции: `## ERROR ANALYSIS`, `## SUGGESTED DIRECTION`, `## SPECIFIC SUGGESTIONS`, `## PRIORITY`
- Создается объект `TextGradient` с заполненными полями

**Контрастные градиенты:**

Если есть достаточно успешных и неуспешных примеров (`MIN_EXAMPLES_FOR_CONTRASTIVE`):
- Генерируется дополнительный контрастный градиент
- Сравниваются "hard negatives" и "hard positives"
- Используется промпт из `prompts/contrastive.txt`
- Контрастные градиенты получают бонус к приоритету (`CONTRASTIVAE_PRIORITY_BOOST`)

##### Шаг 3: Создание вариантов промптов на основе градиентов

candidates = self._generate_candidates(current_best, gradients)

**Процесс:**

Для каждого градиента:

1. **Генерация вариантов:**
   variants = self.editor.generate_variants(current_prompt, gradient, parent_node)
      - Используется промпт из `prompts/editing.txt`
   - LLM получает:
     - Текущий промпт
     - Анализ ошибок из градиента
     - Предложенное направление
     - Конкретные рекомендации
   - LLM генерирует несколько вариантов улучшенного промпта

2. **Парсинг вариантов:**
   - `VariantParser` извлекает варианты из ответа LLM
   - Каждый вариант создается как `PromptNode` с:
     - Новым текстом промпта
     - Ссылкой на родительский узел
     - Операцией редактирования (`EditOperation`)
     - Ссылкой на исходный градиент

3. **Фильтрация дубликатов:**
   - Вычисляется семантическое расстояние между промптами
   - Удаляются варианты с расстоянием < `SIMILARITY_THRESHOLD`

##### Шаг 4: Оценка кандидатов

evaluated_candidates = self._evaluate_candidates(candidates, validation_examples)**Процесс:**

Для каждого кандидата:

1. **Проверка кэша:**
   - Если промпт уже оценивался (по хэшу), пропускается

2. **Выполнение промпта:**
   - Промпт выполняется на обучающих примерах
   - Сохраняются фактические ответы в `actual_output`

3. **Вычисление метрик:**
   - **Accuracy**: правильность ответов (через LLM-judge)
   - **F1**: семантическое перекрытие
   - **Safety**: безопасность ответов
   - **Robustness**: устойчивость к вариациям
   - **Efficiency**: эффективность и краткость

4. **Композитная оценка:**  
   `composite_score = sum(metric * weight for metric, weight in METRIC_WEIGHTS.items())`
5. **Разделение примеров:**
   - Успешные примеры → `evaluation_examples["success"]`
   - Провалы → `evaluation_examples["failures"]`

6. **Сохранение в историю:**
   - Узел добавляется в `HistoryManager`
   - Обновляются индексы по поколениям и источникам

##### Шаг 5: Выбор лучшего кандидата

`best_candidate = self._select_best_candidate(evaluated_candidates)` - Кандидаты сортируются по `composite_score()`
- Выбирается лучший
- Если улучшение >= `MIN_IMPROVEMENT`, он становится новым `current_best`

**Early stopping:**
- Если улучшений нет `PATIENCE` итераций подряд, локальная оптимизация останавливается

---

#### Этап 2.2: Глобальная оптимизация

**Триггеры глобального шага:**

1. **Регулярный интервал:** `generation % GLOBAL_TRIGGER_INTERVAL == 0`
2. **Застой:** средняя схожесть лучших узлов > `STAGNATION_SIMILARITY_THRESHOLD`
3. **Низкое разнообразие:** среднее расстояние между узлами < `LOW_DIVERSITY_THRESHOLD`

**Процесс глобальной оптимизации:**

##### Шаг 1: Анализ истории
`history_analysis = self._analyze_history()`  

**Анализируется:**
1. **Лучшие узлы:**
   - Топ-K узлов по композитной оценке
   - Их промпты и метрики

2. **Паттерны успешных операций:**
   - Какие типы операций (`OperationType`) чаще приводят к улучшениям
   - Общие подпоследовательности операций в успешных траекториях

3. **Застой:**
   - Средняя схожесть лучших узлов
   - Прогресс за последние поколения

4. **Разнообразие:**
   - Попарные расстояния между промптами
   - Оценка необходимости диверсификации

5. **Лучшие элементы:**
   - Общие фразы из успешных промптов
   - Частотный анализ слов

6. **Неудачные направления:**
   - Операции, часто встречающиеся в плохих промптах
   - Направления, которых стоит избегать

7. **Неисследованные области:**
   - Редко используемые типы операций
   - Недостаточное использование глобальных стратегий

##### Шаг 2: Генерация глобальных стратегий

`strategies = self._generate_global_strategies(history_analysis)`

**Процесс:**

1. **Создание промпта для LLM:**
   - Используется шаблон из `prompts/strategy.txt`
   - LLM получает полный анализ истории

2. **Генерация стратегий:**
   - LLM предлагает стратегии улучшения:
     - `COMBINE`: комбинирование лучших промптов
     - `RESTRUCTURE`: структурная реорганизация
     - `DIVERSIFY`: создание разнообразного промпта
     - `SIMPLIFY`: упрощение
     - `EXPAND`: расширение
     - `SPECIALIZE`: специализация

3. **Парсинг:**
   - `StrategyParser` извлекает стратегии из ответа
   - Каждая стратегия содержит:
     - Тип
     - Описание
     - Обоснование
     - Конкретное действие

##### Шаг 3: Применение стратегий

`candidates = self._apply_strategies(strategies, history_analysis, current_generation)`  

**Для каждой стратегии:**

1. **Выбор обработчика:**
   - Каждый тип стратегии имеет свой метод в `PromptEditor`:
     - `apply_combine_strategy()` → комбинирование промптов
     - `apply_restructure_strategy()` → реструктуризация
     - `apply_diversify_strategy()` → диверсификация
     - и т.д.

2. **Создание нового промпта:**
   - LLM применяет стратегию к лучшему промпту
   - Создается новый `PromptNode` с `source=GLOBAL`

3. **Локальная доработка:**
   - Каждый глобальный кандидат дополнительно оптимизируется локально
   - Это позволяет "отполировать" структурные изменения

##### Шаг 4: Оценка глобальных кандидатов

- Аналогично оценке локальных кандидатов
- Результаты анализируются для определения успешных стратегий

---

#### Этап 2.3: Обновление популяции

`population = self._select_population(new_candidates, population_size=POPULATION_SIZE)`  

**Стратегия отбора:**

1. **Абсолютно лучший кандидат:** всегда включается
2. **Pareto-front:** узлы, не доминируемые другими по множественным метрикам
3. **Топ по композитной оценке:** дополнение до размера популяции
4. **Разнообразие:** если места остались, добавляются наиболее разнообразные варианты

---

### Фаза 3: Финальная оценка и сохранение

1. **Оценка на тестовом наборе:**
   - Лучший промпт оценивается на тестовых примерах
   - Вычисляются финальные метрики

2. **Сохранение результатов:**
   - `optimization_history.json`: полная история узлов
   - `optimization_report.json`: сводный отчет
   - `best_prompt.txt`: лучший промпт
   - `trajectory.txt`: визуализация траектории оптимизации

---

## Детали генерации градиентов

### Типы градиентов

1. **Стандартный градиент:**
   - Анализ конкретных провалов
   - Предложения по улучшению

2. **Кластеризованный градиент:**
   - Группировка провалов по типам ошибок
   - Отдельный градиент на кластер

3. **Контрастный градиент:**
   - Сравнение успешных и неуспешных примеров
   - Выявление различий

### Промпты для генерации градиентов

**`prompts/analysis.txt`:**
- Анализ ошибок в провалах
- Предложение направления улучшения
- Конкретные рекомендации
- Приоритет градиента

**`prompts/clustering.txt`:**
- Группировка провалов по типам ошибок
- Формат: `CATEGORY: ... EXAMPLES: 1, 2, 3...`

**`prompts/contrastive.txt`:**
- Сравнение hard negatives и hard positives
- Выявление ключевых различий

**`prompts/editing.txt`:**
- Генерация вариантов промпта на основе градиента
- Формат: несколько вариантов в code blocks

### Приоритизация градиентов

Градиенты сортируются по приоритету:
- Контрастные получают бонус `CONTRASTIVAE_PRIORITY_BOOST`
- Приоритет определяется LLM (0.0-1.0)
- По умолчанию: `DEFAULT_PRIORITY = 0.5`

---

## Применение градиентов к промптам

### Процесс редактирования

1. **Получение градиента:**
   - Градиент содержит анализ и рекомендации

2. **Генерация вариантов:**
   - LLM получает текущий промпт и градиент
   - Генерируется несколько вариантов улучшения

3. **Типы операций:**
   - `ADD_INSTRUCTION`: добавление инструкции
   - `MODIFY_INSTRUCTION`: изменение инструкции
   - `ADD_EXAMPLE`: добавление примера
   - `REPHRASE`: переформулировка
   - `RESTRUCTURE`: структурная реорганизация
   - `ADD_CONSTRAINT`: добавление ограничения
   - `CLARIFY`: уточнение

4. **Создание узлов:**
   - Каждый вариант → новый `PromptNode`
   - Сохраняется связь с родителем
   - Записывается операция и исходный градиент

---

## Метрики оценки

### Композитная оценка

`composite_score = (
    accuracy * 0.2 +
    safety * 0.2 +
    robustness * 0.2 +
    efficiency * 0.2 +
    f1 * 0.2
)`

### Метрики

1. **Accuracy:** правильность ответов (бинарная)
2. **F1:** семантическое перекрытие (0.0-1.0)
3. **Safety:** безопасность ответов (бинарная)
4. **Robustness:** устойчивость к вариациям (0.0-1.0)
5. **Efficiency:** эффективность и краткость (бинарная)

Все метрики вычисляются через LLM-judge для семантической оценки.

---

## Управление историей

### Структура данных

- **Дерево узлов:** каждый промпт связан с родителем
- **Индексы:** по поколениям, источникам, оцененным узлам
- **Pareto-front:** лучшие по множественным метрикам

### Анализ истории

- **Успешные операции:** какие типы операций чаще улучшают промпты
- **Траектории:** пути от начального к лучшему промпту
- **Застой:** обнаружение плато в оптимизации
- **Разнообразие:** оценка разнообразия популяции

---

## Конфигурация

Основные параметры в `config.py`:

- `LOCAL_ITERATIONS_PER_GENERATION`: итераций локальной оптимизации
- `LOCAL_CANDIDATES_PER_ITERATION`: количество градиентов за итерацию
- `LOCAL_BATCH_SIZE`: максимальное число примеров в батче
- `MAX_GENERATIONS`: максимальное число поколений
- `POPULATION_SIZE`: размер популяции
- `PATIENCE`: итераций без улучшения до остановки
- `MIN_IMPROVEMENT`: минимальное улучшение для изменения текущего промпта
- `MAX_EXAMPLES_PER_NODE`: максимальное число примеров на узел

